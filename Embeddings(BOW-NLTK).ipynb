{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9647b9e9-0d45-4c80-89db-822269c8b03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inbuilt IMDB dataset loaded!\n",
      "Train size: 25000\n",
      "Test size: 25000\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "\n",
      "DataFrame created from inbuilt dataset.\n",
      "                                              review  sentiment\n",
      "0  ? this film was just brilliant casting locatio...          1\n",
      "1  ? big hair big boobs bad music and a giant saf...          0\n",
      "2  ? this has to be one of the worst films of the...          0\n",
      "3  ? the ? ? at storytelling the traditional sort...          1\n",
      "4  ? worst mistake of my life br br i picked this...          0\n",
      "\n",
      "Cleaned Review Example:\n",
      " ? film just brilliant casting location scenery story direction everyone's really suited played just imagine robert ? amazing actor director ? father came scottish island loved fact real connection film witty remarks film great just brilliant bought film soon released ? recommend watch fly fishing amazing really cried end sad know say film good definitely ? little boy's played ? norman paul just brilliant children left ? list think stars play grown big profile film children amazing praised don't think story lovely true someone's life shared\n",
      "\n",
      "Training samples: 4000\n",
      "Testing samples: 1000\n",
      "\n",
      "BOW Shape: (4000, 9487)\n",
      "\n",
      "Naive Bayes Accuracy: 0.646\n",
      "SVM Accuracy: 0.819\n",
      "Random Forest Accuracy: 0.823\n",
      "\n",
      "Random Forest (N-Grams) Accuracy: 0.819\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# IMPORTS\n",
    "# ------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ML imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# LOAD INBUILT IMDB DATASET\n",
    "# ------------------------------------------------------\n",
    "# We use Keras built-in IMDB dataset (no CSV needed)\n",
    "from keras.datasets import imdb\n",
    "\n",
    "# Load top 10,000 words from IMDB\n",
    "(X_train_raw, y_train_raw), (X_test_raw, y_test_raw) = imdb.load_data(num_words=10000)\n",
    "\n",
    "print(\"Inbuilt IMDB dataset loaded!\")\n",
    "print(\"Train size:\", len(X_train_raw))\n",
    "print(\"Test size:\", len(X_test_raw))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# DECODE INTEGER SEQUENCES TO TEXT\n",
    "# IMDB gives word indices, so we convert them back to words.\n",
    "# ------------------------------------------------------\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = {value: key for key, value in word_index.items()}\n",
    "\n",
    "def decode_review(encoded_review):\n",
    "    return \" \".join([reverse_word_index.get(i - 3, \"?\") for i in encoded_review])\n",
    "\n",
    "# Convert all encoded reviews to raw text\n",
    "X_train_text = [decode_review(review) for review in X_train_raw]\n",
    "X_test_text  = [decode_review(review) for review in X_test_raw]\n",
    "\n",
    "# Merge them like CSV-style dataset\n",
    "X_total = X_train_text + X_test_text\n",
    "y_total = np.concatenate((y_train_raw, y_test_raw))\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\"review\": X_total, \"sentiment\": y_total})\n",
    "df = df[:5000]  # Take only 5000 reviews for faster training\n",
    "\n",
    "print(\"\\nDataFrame created from inbuilt dataset.\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# REMOVE HTML TAGS\n",
    "# ------------------------------------------------------\n",
    "def remove_html(text):\n",
    "    return re.sub(re.compile('<.*?>'), '', text)\n",
    "\n",
    "df['review'] = df['review'].apply(remove_html)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# REMOVE STOPWORDS (using sklearn)\n",
    "# ------------------------------------------------------\n",
    "stop_words = list(ENGLISH_STOP_WORDS)\n",
    "\n",
    "df['review'] = df['review'].apply(\n",
    "    lambda x: \" \".join([word for word in x.split() if word.lower() not in stop_words])\n",
    ")\n",
    "\n",
    "print(\"\\nCleaned Review Example:\\n\", df['review'].iloc[0])\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# SPLIT DATA\n",
    "# ------------------------------------------------------\n",
    "X = df['review']\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nTraining samples:\", X_train.size)\n",
    "print(\"Testing samples:\", X_test.size)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# BAG OF WORDS\n",
    "# ------------------------------------------------------\n",
    "cv = CountVectorizer(max_features=10000)\n",
    "X_train_cv = cv.fit_transform(X_train).toarray()\n",
    "X_test_cv = cv.transform(X_test).toarray()\n",
    "\n",
    "print(\"\\nBOW Shape:\", X_train_cv.shape)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# MODEL 1: NAIVE BAYES\n",
    "# ------------------------------------------------------\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_cv, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test_cv)\n",
    "\n",
    "print(\"\\nNaive Bayes Accuracy:\", accuracy_score(y_test, y_pred_gnb))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# MODEL 2: SVM (RBF)\n",
    "# ------------------------------------------------------\n",
    "svc = SVC()\n",
    "svc.fit(X_train_cv, y_train)\n",
    "y_pred_svc = svc.predict(X_test_cv)\n",
    "\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svc))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# MODEL 3: RANDOM FOREST\n",
    "# ------------------------------------------------------\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_cv, y_train)\n",
    "y_pred_rf = rf.predict(X_test_cv)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# N-GRAM FEATURES (1-gram + 2-gram)\n",
    "# ------------------------------------------------------\n",
    "cv_ngram = CountVectorizer(ngram_range=(1, 2), max_features=10000)\n",
    "X_train_ng = cv_ngram.fit_transform(X_train).toarray()\n",
    "X_test_ng = cv_ngram.transform(X_test).toarray()\n",
    "\n",
    "rf_ng = RandomForestClassifier()\n",
    "rf_ng.fit(X_train_ng, y_train)\n",
    "y_pred_ng = rf_ng.predict(X_test_ng)\n",
    "\n",
    "print(\"\\nRandom Forest (N-Grams) Accuracy:\", accuracy_score(y_test, y_pred_ng))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
